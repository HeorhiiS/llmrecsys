{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "# unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "# users = pd.read_csv('ml-latest/users.csv', sep=',',\n",
    "#  header=None, names=unames, engine='python', encoding='latin-1')\n",
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table('ml-1m/ratings.dat', sep='::',\n",
    " header=None, names=rnames, engine='python', encoding='latin-1')\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('ml-1m/movies.dat', sep='::',\n",
    " header=None, names=mnames, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[ratings[\"rating\"] >= 4]  # Remove disliked movies\n",
    "ratings = ratings.merge(movies, on=\"movie_id\")  # Add in titles\n",
    "merged_ratings = pd.merge(ratings[['user_id', 'movie_id', 'rating']], movies[['movie_id', 'title','genres']], on='movie_id')\n",
    "merged_ratings = merged_ratings.drop_duplicates(subset=['user_id', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0 \n",
    "instruction = \"Given a list of liked movies, recommend 4 more movies the user would like.\"\n",
    "prompt_list = []\n",
    "for _, user in merged_ratings.groupby(\"user_id\"): \n",
    "   \n",
    "        if user.shape[0] >= 10:\n",
    "                count +=1\n",
    "                \n",
    "                # Get amount of 10 movie blocks in user.shape[0]\n",
    "                num_blocks = int(user.shape[0]/10)\n",
    "                # For each block, create a fine-tuning example\n",
    "                for i in range(num_blocks):\n",
    "                        # Get 10 movies\n",
    "                        movies = user.iloc[i*10:(i+1)*10]\n",
    "                        # fitst 6 movies are the input, last 4 are the output in string form\n",
    "                        input_str = movies.iloc[:6].title.str.cat(sep=', ')\n",
    "                        output_str = movies.iloc[6:].title.str.cat(sep=', ')\n",
    "                        \n",
    "                        prompt = {\n",
    "                                \"instruction\": f\"{instruction}\",\n",
    "                                \"input\": f\"{input_str} =>\",\n",
    "                                \"output\": f\"{output_str}\"\n",
    "                                }\n",
    "                        prompt_list.append(prompt)\n",
    "\n",
    "\n",
    "                        \n",
    "        \n",
    "data_len = len(prompt_list)           \n",
    "                \n",
    "print('Prepared fine-tuning and evaluation datasets')     \n",
    "print(f'Tuning set is of size {data_len}, given even amount for train/eval, the respective sizes of sets are {int(data_len*0.85)} for training and {int(data_len*0.15)} for testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('llama_train.json', 'w') as outfile:\n",
    "    json.dump(prompt_list[:int(data_len*0.85)], outfile)\n",
    "\n",
    "with open('llama_eval.json', 'w') as outfile:\n",
    "    json.dump(prompt_list[int(data_len*0.85):], outfile)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
